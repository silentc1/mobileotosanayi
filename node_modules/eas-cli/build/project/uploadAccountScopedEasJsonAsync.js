"use strict";
Object.defineProperty(exports, "__esModule", { value: true });
exports.uploadAccountScopedEasJsonAsync = void 0;
const tslib_1 = require("tslib");
const chalk_1 = tslib_1.__importDefault(require("chalk"));
const node_fs_1 = tslib_1.__importDefault(require("node:fs"));
const node_path_1 = tslib_1.__importDefault(require("node:path"));
const generated_1 = require("../graphql/generated");
const uploads_1 = require("../uploads");
const files_1 = require("../utils/files");
const progress_1 = require("../utils/progress");
/**
 * Uploads the `eas.json` file to GCS as account-scoped object.
 * Used in workflows. Takes care of logging progress.
 */
async function uploadAccountScopedEasJsonAsync({ graphqlClient, accountId, projectDir, }) {
    const easJsonFilePath = node_path_1.default.join(projectDir, 'eas.json');
    const easJsonFileStat = await node_fs_1.default.promises.stat(easJsonFilePath);
    if (easJsonFileStat.size > 1024 * 1024) {
        throw new Error('eas.json is too big. Maximum allowed size is 1MB.');
    }
    const easJsonBucketKey = await (0, uploads_1.uploadAccountScopedFileAtPathToGCSAsync)(graphqlClient, {
        accountId,
        type: generated_1.AccountUploadSessionType.WorkflowsProjectSources,
        path: easJsonFilePath,
        handleProgressEvent: (0, progress_1.createProgressTracker)({
            total: easJsonFileStat.size,
            message: ratio => `Uploading eas.json to EAS (${(0, files_1.formatBytes)(easJsonFileStat.size * ratio)} / ${(0, files_1.formatBytes)(easJsonFileStat.size)})`,
            completedMessage: (duration) => `Uploaded eas.json to EAS ${chalk_1.default.dim(duration)}`,
        }),
    });
    return { easJsonBucketKey };
}
exports.uploadAccountScopedEasJsonAsync = uploadAccountScopedEasJsonAsync;
